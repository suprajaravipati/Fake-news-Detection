{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(row):\n",
    "    text = row['text']\n",
    "    text= text.lower()\n",
    "    \n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = regex.sub(' ', text)\n",
    "    \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    text = text.split(' ')\n",
    "\n",
    "    text = [word for word in text if word.isalpha()]\n",
    "    \n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed_text = []\n",
    "    for word in text:\n",
    "        #stemmed_text.append(stemmer.stem(word))\n",
    "        stemmed_text.append(lemmatizer.lemmatize(word))\n",
    "        \n",
    "    text = \" \".join(stemmed_text)\n",
    "    row['text'] = text\n",
    "    return(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data 534\n"
     ]
    }
   ],
   "source": [
    " \n",
    "path = 'C:/Users/shash/Spring Projects/Predictive/Train.csv'\n",
    "licensing_df = pd.read_csv(path)\n",
    "title=licensing_df[licensing_df['text'].isna()]['title']\n",
    "print(\"Number of missing data\",len(title))\n",
    "licensing_df.loc[licensing_df['text'].isna(),'text']=title\n",
    "\n",
    "columns = ['text', 'type']\n",
    "data = licensing_df[columns]\n",
    "data = data.apply(preprocess, axis = 1)\n",
    "X = data['text']\n",
    "y = data['type']\n",
    "\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licensing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>Governor extends Flint water emergency as stat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Michigan Governor Rick ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>DEMOCRATS CONVENIENTLY FORGET 6,000 Prisoners ...</td>\n",
       "      <td>Democrats are calling for President Trump s sc...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>Mexico recognizes Honduran president as winner...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Mexico recognized Hond...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-20</td>\n",
       "      <td>BOOM! Wikileaks Shows Hillary Speech To Banker...</td>\n",
       "      <td>No wonder she didn t want anyone to see her sp...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>Paul Ryan says confident tax reform will pass ...</td>\n",
       "      <td>WASHINGTON (Reuters) - Republicans will be abl...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>Boeing, aerospace manufacturers back U.S. tax ...</td>\n",
       "      <td>SEATTLE (Reuters) - Boeing Co and about 90 oth...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>Saudi Prince Reminds Donald Trump: I Bailed Yo...</td>\n",
       "      <td>While Donald Trump continues to paint himself ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>ADMIRAL JAMES “ACE” LYONS WARNS: What The Join...</td>\n",
       "      <td>Admiral Ace Lyons has warned us all before in ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>Syrian army nears Islamic State stronghold al-...</td>\n",
       "      <td>BEIRUT (Reuters) - Syria s army and its allies...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2016-03-11  Governor extends Flint water emergency as stat...   \n",
       "1  2017-10-09  DEMOCRATS CONVENIENTLY FORGET 6,000 Prisoners ...   \n",
       "2  2018-02-01  Mexico recognizes Honduran president as winner...   \n",
       "3  2016-11-20  BOOM! Wikileaks Shows Hillary Speech To Banker...   \n",
       "4  2017-07-06  Paul Ryan says confident tax reform will pass ...   \n",
       "5  2018-02-12  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "6  2017-04-26  Boeing, aerospace manufacturers back U.S. tax ...   \n",
       "7  2016-07-28  Saudi Prince Reminds Donald Trump: I Bailed Yo...   \n",
       "8  2016-06-21  ADMIRAL JAMES “ACE” LYONS WARNS: What The Join...   \n",
       "9  2017-11-18  Syrian army nears Islamic State stronghold al-...   \n",
       "\n",
       "                                                text  type  \n",
       "0  WASHINGTON (Reuters) - Michigan Governor Rick ...  real  \n",
       "1  Democrats are calling for President Trump s sc...  fake  \n",
       "2  MEXICO CITY (Reuters) - Mexico recognized Hond...  real  \n",
       "3  No wonder she didn t want anyone to see her sp...  fake  \n",
       "4  WASHINGTON (Reuters) - Republicans will be abl...  real  \n",
       "5  WASHINGTON (Reuters) - The special counsel inv...  real  \n",
       "6  SEATTLE (Reuters) - Boeing Co and about 90 oth...  real  \n",
       "7  While Donald Trump continues to paint himself ...  fake  \n",
       "8  Admiral Ace Lyons has warned us all before in ...  fake  \n",
       "9  BEIRUT (Reuters) - Syria s army and its allies...  real  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licensing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(10, True, 1)\n",
    "predictions=[-1]*len(data)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "    X_train=X[train]\n",
    "    y_train=y[train]\n",
    "    X_test=X[test]\n",
    "    y_test=y[test]\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions1 = model.predict(X_test)\n",
    "    count=0\n",
    "    for i in y_test.index:\n",
    "        predictions[i]=predictions1[count]\n",
    "        count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.98      0.97     19865\n",
      "        real       0.98      0.95      0.96     18135\n",
      "\n",
      "    accuracy                           0.97     38000\n",
      "   macro avg       0.97      0.97      0.97     38000\n",
      "weighted avg       0.97      0.97      0.97     38000\n",
      "\n",
      "Accuracy : 96.67105263157895\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y, predictions)\n",
    "print(clf_report)\n",
    "print('Accuracy :',sum(y==predictions)*100/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(10, True, 1)\n",
    "predictions=[-1]*len(data)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "    X_train=X[train]\n",
    "    y_train=y[train]\n",
    "    X_test=X[test]\n",
    "    y_test=y[test]\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions1 = model.predict(X_test)\n",
    "    count=0\n",
    "    for i in y_test.index:\n",
    "        predictions[i]=predictions1[count]\n",
    "        count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      1.00      1.00     19865\n",
      "        real       1.00      1.00      1.00     18135\n",
      "\n",
      "    accuracy                           1.00     38000\n",
      "   macro avg       1.00      1.00      1.00     38000\n",
      "weighted avg       1.00      1.00      1.00     38000\n",
      "\n",
      "Accuracy : 99.67105263157895\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y, predictions)\n",
    "print(clf_report)\n",
    "print('Accuracy :',sum(y==predictions)*100/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(10, True, 1)\n",
    "predictions=[-1]*len(data)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "    X_train=X[train]\n",
    "    y_train=y[train]\n",
    "    X_test=X[test]\n",
    "    y_test=y[test]\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions1 = model.predict(X_test)\n",
    "    count=0\n",
    "    for i in y_test.index:\n",
    "        predictions[i]=predictions1[count]\n",
    "        count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      1.00      1.00     19865\n",
      "        real       1.00      1.00      1.00     18135\n",
      "\n",
      "    accuracy                           1.00     38000\n",
      "   macro avg       1.00      1.00      1.00     38000\n",
      "weighted avg       1.00      1.00      1.00     38000\n",
      "\n",
      "Accuracy : 99.62105263157895\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y, predictions)\n",
    "print(clf_report)\n",
    "print('Accuracy :',sum(y==predictions)*100/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(10, True, 1)\n",
    "predictions=[-1]*len(data)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "    X_train=X[train]\n",
    "    y_train=y[train]\n",
    "    X_test=X[test]\n",
    "    y_test=y[test]\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions1 = model.predict(X_test)\n",
    "    count=0\n",
    "    for i in y_test.index:\n",
    "        predictions[i]=predictions1[count]\n",
    "        count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.99      1.00     19865\n",
      "        real       0.99      1.00      1.00     18135\n",
      "\n",
      "    accuracy                           1.00     38000\n",
      "   macro avg       1.00      1.00      1.00     38000\n",
      "weighted avg       1.00      1.00      1.00     38000\n",
      "\n",
      "Accuracy : 99.63421052631578\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y, predictions)\n",
    "print(clf_report)\n",
    "print('Accuracy :',sum(y==predictions)*100/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(10, True, 1)\n",
    "predictions=[-1]*len(data)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "    X_train=X[train]\n",
    "    y_train=y[train]\n",
    "    X_test=X[test]\n",
    "    y_test=y[test]\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions1 = model.predict(X_test)\n",
    "    count=0\n",
    "    for i in y_test.index:\n",
    "        predictions[i]=predictions1[count]\n",
    "        count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report = classification_report(y, predictions)\n",
    "print(clf_report)\n",
    "print('Accuracy :',sum(y==predictions)*100/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
